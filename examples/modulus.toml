# ============================
# Modulus TOML Schema v0.1
# ============================

# ----------------------------
# [openai.<name>]
# Defines a model provider
# ----------------------------
[provider.openai]
type = "openai"
api_key = "@var:OPENAI_API_KEY" # use @env:OPENAI_API_KEY if it is defined as an environment variable

# ----------------------------
# [llm.<name>]
# Defines a language model
# ----------------------------
[llm.default]
provider = "openai"
model = "gpt-4o"
temperature = 0.7
max_tokens = 2048

[llm.fast]
provider = "openai"
model = "gpt-3.5-turbo"
temperature = 0.0

# ----------------------------
# [embedding.<name>]
# Defines an embedding model
# ----------------------------
[embedding.ada]
provider = "openai"
model = "text-embedding-ada-002"

# ----------------------------
# [memory.<name>]
# Defines vector memory store
# ----------------------------
[memory.vectorstore]
type = "chroma"
persist = true
namespace = "main"
embedding_model = "text-embedding-ada-002"

# ----------------------------
# [[tool]]
# External API, function, or memory lookup
# ----------------------------
[tool.foo]
type = "function"
function = "functions/foo.foofn"

# ----------------------------
# [[agent]]
# Defines an AI persona
# ----------------------------
[agent.researcher]
prompt = "@file:prompts/researcher.prompt"
llm = "default"
tools = []
memory = "vectorstore"

[agent.analyst]
prompt = "@file:prompts/analyst.prompt"
llm = "fast"
tools = []
memory = "vectorstore"

# ----------------------------
# [task.<name>]
# Pipeline or multi-agent orchestration
# ----------------------------
[task.qa]
description = "Full question answering pipeline"
flow = ["researcher", "analyst"]
input_schema = { question = "string" }
output_schema = { answer = "string", citations = "array" }

# ----------------------------
# [deployment.<name>]
# Hosting configuration
# ----------------------------
[deployment.default]
runtime = "fastapi"
expose = ["task.qa"]
port = 8080

# ----------------------------
# [vars]
# Secrets and environment substitutions
# ----------------------------
[vars]
OPENAI_API_KEY = "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"
