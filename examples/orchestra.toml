# === LLM Definitions ===
[llm.default]
provider = "openai"
model = "gpt-4o"
temperature = 0.2

[llm.retriever]
provider = "openai"
model = "gpt-3.5-turbo"
temperature = 0.0

# === Memory Backends ===
[memory.vectorstore]
type = "chroma"
persist = true
namespace = "main"
embedding_model = "text-embedding-ada-002"

# === Tools ===
[[tool]]
name = "search"
type = "api"
endpoint = "https://api.serpapi.com/search"
method = "GET"
headers = { Authorization = "Bearer ${SERPAPI_KEY}" }

[[tool]]
name = "calculator"
type = "function"
command = "builtin:math.eval"

[[tool]]
name = "doc_lookup"
type = "vector_lookup"
memory = "vectorstore"

# === Agents ===
[[agent]]
name = "researcher"
role = "Information seeker"
goal = "Research and summarize queries using web and documents."
llm = "default"
tools = ["search", "doc_lookup"]
memory = "vectorstore"

[[agent]]
name = "analyst"
role = "Data processor"
goal = "Analyze results and provide structured insights."
llm = "retriever"
tools = ["calculator"]
memory = "vectorstore"

# === Tasks ===
[task.question_answering]
description = "End-to-end question answering"
entry_agent = "researcher"
handoff_to = "analyst"
input_schema = { question = "string" }
output_schema = { answer = "string", citations = "array" }

# === Deployment ===
[deployment.default]
runtime = "fastapi"
expose = ["task.question_answering"]
port = 8080
auth_token = "${DEPLOY_AUTH_TOKEN}"

# === Variables / Secrets ===
[vars]
SERPAPI_KEY = "your-serpapi-key"
DEPLOY_AUTH_TOKEN = "secret-token-123"

